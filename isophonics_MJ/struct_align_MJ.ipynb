{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare aligned audio segments\n",
    "Compare music similarity between similar structural segments by hierarchically decomposing structure and finding segment alignment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Library importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computation\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.interpolate import interp2d\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "#Data Processing\n",
    "import sklearn.cluster\n",
    "import sklearn\n",
    "\n",
    "#Audio\n",
    "import librosa\n",
    "from librosa import display\n",
    "\n",
    "#System\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#Pickling\n",
    "import dill\n",
    "\n",
    "#Reading\n",
    "import reader\n",
    "import segment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Load annotations and audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose parent directory containing audiofiles and annotations\n",
    "directory = '/Users/chris/Google Drive/Publication Files/CMMR2021/Datasets/isophonics_MJ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotation paths\n",
    "lab_paths = reader.read_paths(directory, '.lab')\n",
    "# Load to dictionary and fix annotation data\n",
    "labs = reader.load_lab(lab_paths)\n",
    "print(\"Loaded annotations.\")\n",
    "\n",
    "# Cross reference audio with annotations\n",
    "ref = reader.ref_paths(directory, directory)\n",
    "\n",
    "# Load audio paths\n",
    "audio_paths = reader.read_paths(directory, '.flac')\n",
    "file_no = len(audio_paths)\n",
    "# Load audio\n",
    "audio = {}\n",
    "sr = 22050\n",
    "for i,path in enumerate(audio_paths):\n",
    "    audio[os.path.basename(path)[:-5]] = librosa.load(path, sr=sr, mono=True)\n",
    "    sys.stdout.write(\"\\rLoaded %i/%i pieces.\" % (i+1, file_no))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Get segments from each method"
   ]
  },
  {
   "source": [
    "### >> Matching Segment Selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "#### >>> Compute segmentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmin = 2\n",
    "kmax = 7\n",
    "mss_seg_ids = {}\n",
    "mss_f = {} #formatted segments\n",
    "for p in audio_paths:\n",
    "    name = os.path.basename(p[:-5])\n",
    "    y, sr = audio[name]\n",
    "    mss_seg_ids[name], mss_f[name] = segment.segment(y, sr, kmin, kmax)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the segments\n",
    "n_to_plot = 2\n",
    "fig, axs = plt.subplots(n_to_plot, 1, figsize=(20, 4*n_to_plot))\n",
    "for i,p in enumerate(audio_paths):\n",
    "    name = os.path.basename(p[:-5])\n",
    "    axs[i].matshow(mss_seg_ids[name], aspect=10)\n",
    "    axs[i].set(title=name)\n",
    "    if i>=n_to_plot-1:\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### >>> Find segment hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for p in audio_paths:\n",
    "    name = os.path.basename(p[:-5])\n",
    "#traverse hierarchies, song 1\n",
    "for i in range(kmax-kmin):\n",
    "    #traverse segments, song 1\n",
    "    for j in range(len(mss_f[name][2][i])):\n",
    "    #traverse hierarchies, song 2\n",
    "        for k in range(kmax-kmin):\n",
    "            #traverse segments, song 2\n",
    "            for l in range(len(all_formatted_beats[s2][k])):\n",
    "                if all_formatted_beats[s1][i][j][1] == all_formatted_beats[s2][k][l][1]:\n",
    "                    hits.append([i,j,k,l])\n",
    "print(hits)\n"
   ]
  },
  {
   "source": [
    "### >> Pad to maximum"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### >>> Pad annotation data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get maximum length of any audiofile in frames\n",
    "max_length = 0\n",
    "for p in audio_paths:\n",
    "    name = os.path.basename(p[:-5])\n",
    "    if len(audio[name][0]) > max_length:\n",
    "        max_length = len(audio[name][0])\n",
    "\n",
    "labs_PM = {}\n",
    "for p in audio_paths:\n",
    "    name = os.path.basename(p[:-5])\n",
    "    labs_PM[name] = reader.vectorize(lab=labs[name], sr=sr, start_f=0, end_f=max_length)"
   ]
  },
  {
   "source": [
    "#### >>> PM scores"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### >> Pad pairwise"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### >>> Compute pairwise padding of annotation data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "essentially create directed distance matrix by returning \n",
    "segments of A in comparison with B when querrying labs_PP[A][B]\n",
    "and segments of B in comparison with A when querrying labs_PP[B][A]\n",
    "\"\"\"\n",
    "labs_PP = {}\n",
    "for p1 in audio_paths:\n",
    "    name1 = os.path.basename(p1)[:-5]\n",
    "    d = {} #2D dictionary\n",
    "    for p2 in audio_paths\n",
    "        name2 = os.path.basename(p2)[:-5]\n",
    "        #find length of longer audiofile\n",
    "        max_length = max(len(audio[name1][0]), len(audio[name2][0]))\n",
    "        d[name2] = reader.vectorize(lab=labs[name1], sr=sr, start_f=0, end_f=max_length)\n",
    "    labs_PP[name1] = d\n"
   ]
  },
  {
   "source": [
    "#### >>> PP scores"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### >> Truncate to minimum\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### >>> Truncate annotation data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get minimum length of any audiofile\n",
    "min_length = len((audio[os.path.basename(audio_paths[0])[:-5]])[0])\n",
    "for p in audio_paths:\n",
    "    name = os.path.basename(p[:-5])\n",
    "    if len(audio[name][0]) < min_length:\n",
    "        min_length = len(audio[name][0])\n",
    "\n",
    "labs_TM = {}\n",
    "for p in audio_paths:\n",
    "    name = os.path.basename(p[:-5])\n",
    "    labs_TM[name] = reader.vectorize(lab=labs[name], sr=sr, start_f=0, end_f=min_length)"
   ]
  },
  {
   "source": [
    "#### >>> TM scores"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### >> Truncate pairwise"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### >>> Compute pairwise truncation of annotation data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "essentially create directed distance matrix by returning \n",
    "segments of A in comparison with B when querrying labs_PP[A][B]\n",
    "and segments of B in comparison with A when querrying labs_PP[B][A]\n",
    "\"\"\"\n",
    "labs_TP = {}\n",
    "for p1 in audio_paths:\n",
    "    name1 = os.path.basename(p1)[:-5]\n",
    "    d = {} #2D dictionary\n",
    "    for p2 in audio_paths\n",
    "        name2 = os.path.basename(p2)[:-5]\n",
    "        #find length of longer audiofile\n",
    "        max_length = min(len(audio[name1][0]), len(audio[name2][0]))\n",
    "        d[name2] = reader.vectorize(lab=labs[name1], sr=sr, start_f=0, end_f=min_length)\n",
    "    labs_TP[name1] = d"
   ]
  },
  {
   "source": [
    "#### >>> TP scores"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### >> Fixed length from middle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### >> Get annotations for given interval around the middle of the audio"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_FL15 = {}\n",
    "labs_FL30 = {}\n",
    "labs_FL60 = {}\n",
    "for p in audio_paths:\n",
    "\n",
    "    name = os.path.basename(p[:-5])\n",
    "    audio_length = len(audio[name][0]) #get audio length\n",
    "\n",
    "    start_f = int(audio_length/2) - int(7.5*sr) #get start of segment, centered around the middle\n",
    "    end_f = start_f + 15*sr #get end of segment, centered around the middle\n",
    "    labs_FL15[name] = reader.vectorize(lab=labs[name], sr=sr, start_f=start_f, end_f=end_f)\n",
    "\n",
    "    start_f = int(audio_length/2)- 15*sr #get start of segment, centered around the middle\n",
    "    end_f = start_f + 30*sr #get end of segment, centered around the middle\n",
    "    labs_FL30[name] = reader.vectorize(lab=labs[name], sr=sr, start_f=start_f, end_f=end_f)\n",
    "\n",
    "    start_f = int(audio_length/2) - 30*sr #get start of segment, centered around the middle\n",
    "    end_f = start_f + 60*sr #get end of segment, centered around the middle\n",
    "    labs_FL60[name] = reader.vectorize(lab=labs[name], sr=sr, start_f=start_f, end_f=end_f)"
   ]
  },
  {
   "source": [
    "#### >>> FL scores"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python394jvsc74a57bd03043fb70fd2df7e9357aa7649f2e828b48d620d4fe7e46ef23f0096f1ce7edaf",
   "display_name": "Python 3.9.4 64-bit ('.venv': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "3043fb70fd2df7e9357aa7649f2e828b48d620d4fe7e46ef23f0096f1ce7edaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}